% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gdfa.R
\name{gdfa}
\alias{gdfa}
\title{Gamma Discriminant Function Approach for Estimating Odds Ratio with Exposure
Potentially Subject to Multiplicative Lognormal Measurement Error}
\usage{
gdfa(y, xtilde, c = NULL, constant_or = TRUE, merror = FALSE,
  integrate_tol = 1e-08, integrate_tol_hessian = integrate_tol,
  estimate_var = TRUE, fix_posdef = TRUE, ...)
}
\arguments{
\item{y}{Numeric vector of Y values.}

\item{xtilde}{Numeric vector (or list of numeric vectors, if there are
replicates) of Xtilde values.}

\item{c}{Numeric matrix with \strong{C} values (if any), with one row for
each subject. Can be a vector if there is only 1 covariate.}

\item{constant_or}{Logical value for whether to assume a constant odds ratio
for X, which means that gamma_y = 0. If \code{NULL}, model is fit with and
without this assumption, and a likelihood ratio test is performed to test it.}

\item{merror}{Logical value for whether there is measurement error.}

\item{integrate_tol}{Numeric value specifying the \code{tol} input to
\code{\link{hcubature}}.}

\item{integrate_tol_hessian}{Same as \code{integrate_tol}, but for use when
estimating the Hessian matrix only. Sometimes more precise integration
(i.e. smaller tolerance) helps prevent cases where the inverse Hessian is not
positive definite.}

\item{estimate_var}{Logical value for whether to return variance-covariance
matrix for parameter estimates.}

\item{fix_posdef}{Logical value for whether to repeatedly reduce
\code{integrate_tol_hessian} by factor of 5 and re-estimate Hessian to try
to avoid non-positive definite variance-covariance matrix.}

\item{...}{Additional arguments to pass to \code{\link[stats]{nlminb}}.}
}
\value{
List containing:
\enumerate{
\item Numeric vector of parameter estimates.
\item Variance-covariance matrix.
\item Returned \code{\link[stats]{nlminb}} object from maximizing the
log-likelihood function.
\item Akaike information criterion (AIC).
}

If \code{constant_or = NULL}, two such lists are returned (one under a
constant odds ratio assumption and one not), along with a likelihood ratio
test for \code{H0: gamma_y = 0}, which is equivalent to
\code{H0: odds ratio is constant}.
}
\description{
Assumes exposure given covariates and outcome is a constant-scale Gamma
regression. Exposure measurements can be assumed precise or subject to
multiplicative lognormal measurement error. Parameters are estimated using
maximum likelihood.
}
\examples{
# Load data frame with (Y, X, Xtilde, C) values for 250 subjects and list
# of Xtilde values where 25 subjects have replicates. Xtilde values are
# affected by measurement error. True log-OR = 0.5 and sigsq_m = 0.5.
data(dat_gdfa)
dat <- dat_gdfa$dat
reps <- dat_gdfa$reps

# Estimate log-OR for X and Y adjusted for C using true X values
# (unobservable truth).
fit.unobservable <- gdfa(
  y = dat$y,
  xtilde = dat$x,
  c = dat$c,
  merror = FALSE
)
fit.unobservable$estimates

# Estimate log-OR for X and Y adjusted for C using observed Xtilde values,
# ignoring measurement error.
fit.naive <- gdfa(
  y = dat$y,
  xtilde = dat$xtilde,
  c = dat$c,
  merror = FALSE
)
fit.naive$estimates

# Repeat, but accounting for measurement error. Takes a few minutes to run
# due to numerical integration.
\dontrun{
fit.corrected <- gdfa(
  y = dat$y,
  xtilde = reps,
  c = dat$c,
  merror = TRUE,
  integrate_tol = 1e-4,
  control = list(trace = 1)
)
fit.corrected$estimates
}

# Same as previous, but allowing for non-constant odds ratio.
\dontrun{
fit.nonconstant <- gdfa(
  y = dat$y,
  xtilde = reps,
  c = dat$c,
  constant_or = FALSE,
  merror = TRUE,
  integrate_tol = 1e-4,
  control = list(trace = 1)
)
fit.nonconstant$estimates
}

# Perform likelihood ratio test for H0: odds ratio is constant.
\dontrun{
lrt <- gdfa(
  y = dat$y,
  xtilde = reps,
  c = dat$c,
  constant_or = NULL,
  merror = TRUE,
  integrate_tol = 1e-4,
  control = list(trace = 1)
)
lrt$fit.constant$estimates
}


}
\references{
Whitcomb, B.W., Perkins, N.J., Zhang, Z., Ye, A., and Lyles, R. H. (2012)
"Assessment of skewed exposure in case-control studies with pooling."
\emph{Stat. Med.} \strong{31}: 2461--2472.
}
