% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/logreg_xerrors1.R
\name{logreg_xerrors1}
\alias{logreg_xerrors1}
\title{Logistic Regression with Normal Exposure Subject to Additive Normal Errors}
\usage{
logreg_xerrors1(y, xtilde, c = NULL, prev = NULL, samp_y1y0 = NULL,
  merror = TRUE, approx_integral = TRUE, integrate_tol = 1e-08,
  integrate_tol_hessian = integrate_tol, estimate_var = FALSE, ...)
}
\arguments{
\item{y}{Numeric vector of Y values.}

\item{xtilde}{List of numeric vectors with Xtilde values.}

\item{c}{Numeric matrix with \strong{C} values (if any), with one row for
each subject. Can be a vector if there is only 1 covariate.}

\item{prev}{Numeric value specifying disease prevalence, allowing for valid
estimation of the intercept with case-control sampling. Can specify
\code{samp_y1y0} instead if sampling rates are known.}

\item{samp_y1y0}{Numeric vector of length 2 specifying sampling probabilities
for cases and controls, allowing for valid estimation of the intercept with
case-control sampling. Can specify \code{prev} instead if it's easier.}

\item{merror}{Logical value for whether there is measurement error.}

\item{approx_integral}{Logical value for whether to use the probit
approximation for the logistic-normal integral, to avoid numerically
integrating X's out of the likelihood function.}

\item{integrate_tol}{Numeric value specifying \code{tol} input to
\code{\link[cubature]{hcubature}} for numerical integration.}

\item{integrate_tol_hessian}{Same as \code{integrate_tol}, but for use when
estimating the Hessian matrix only. Sometimes using a smaller value than for
likelihood maximization helps prevent cases where the inverse Hessian is not
positive definite.}

\item{estimate_var}{Logical value for whether to return variance-covariance
matrix for parameter estimates.}

\item{...}{Additional arguments to pass to \code{\link[stats]{nlminb}}.}
}
\value{
List containing:
\enumerate{
\item Numeric vector of parameter estimates.
\item Variance-covariance matrix (if \code{estimate_var = TRUE}).
\item Returned \code{\link[stats]{nlminb}} object from maximizing the
log-likelihood function.
\item Akaike information criterion (AIC).
}
}
\description{
Assumes exposure measurements are subject to additive normal measurement
errors, and exposure given covariates is a normal-errors linear regression.
Some replicates are required for identifiability. Parameters are estimated
using maximum likelihood.
}
\details{
Disease model is:

logit[P(Y = 1|X, \strong{C})] = beta_0 + beta_x X + \strong{beta_c}^T
\strong{C}

Measurement error model is:

Xtilde|X ~ N(0, sigsq_m)

Exposure model is:

X|\strong{C} ~ N(alpha_0 + \strong{alpha_c}^T \strong{C}, sigsq_x.c)
}
\examples{
# Load data frame with (Y, X, Xtilde, C) values for 500 subjects and list of
# Xtilde values where 25 subjects have replicates. Xtilde values are affected
# by measurement error. True parameter values are beta_0 = -0.5 beta_x = 0.2,
# beta_c = 0.1, sigsq_m = 0.5.
data(dat_logreg_xerrors1)
dat <- dat_logreg_xerrors1$dat
reps <- dat_logreg_xerrors1$reps

# Logistic regression of Y vs. (X, C) (unobservable truth).
fit.unobservable <- glm(y ~ x + c, data = dat, family = "binomial")
fit.unobservable$coef

# Logistic regression of Y vs. (Xtilde, C) ignoring measurement error.
fit.naive <- glm(y ~ xtilde + c, data = dat, family = "binomial")
fit.naive$coef

# Logistic regression of Y vs. (Xtilde, C), accounting for measurement error.
# Avoiding numerical integration by using the probit approximation.
fit.approxml <- logreg_xerrors1(
  y = dat$y,
  xtilde = reps,
  c = dat$c,
  approx_integral = TRUE,
)
fit.approxml$theta.hat

# Repeat, but perform numerical integration. Takes a few minutes to run.
\dontrun{
fit.fullml <- logreg_xerrors1(
  y = dat$y,
  xtilde = reps,
  c = dat$c,
  approx_integral = FALSE,
  integrate_tol = 1e-4,
  control = list(trace = 1)
)
fit.fullml$theta.hat
}


}
